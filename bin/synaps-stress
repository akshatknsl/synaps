#!/usr/bin/env python

# Copyright (c) 2012 Samsung SDS Co., LTD
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.

import eventlet
eventlet.monkey_patch()

import os
import sys

possible_topdir = os.path.normpath(os.path.join(os.path.abspath(sys.argv[0]),
                                                os.pardir, os.pardir))
if os.path.exists(os.path.join(possible_topdir, "synaps", "__init__.py")):
    sys.path.insert(0, possible_topdir)

from datetime import datetime, timedelta
import time
import cProfile, pstats, StringIO

from synaps import flags
from synaps import log as logging
from synaps.openstack.common import cfg
from synaps import utils
from synaps.tests import get_cloudwatch_client


FLAGS = flags.FLAGS
flags.FLAGS(sys.argv)
utils.default_flagfile()
logging.setup()
LOG = logging.getLogger()

TESTSTART = datetime.utcnow().replace(second=0, microsecond=0)
if FLAGS.get('stress_backfill'):
    duration = FLAGS.get('stress_interval') * FLAGS.get('stress_times')
    TESTSTART = TESTSTART - (timedelta(seconds=duration))

TESTCASE = "STRESS/" + datetime.now().strftime("%Y%m%d%H%M")

CW = get_cloudwatch_client()
    
def _put_metric(cw, instance_id):
    n = FLAGS.get('stress_metrics_per_instance')
    namespace = TESTCASE
    name = ["metric-%08d" % i for i in range(n)]
    value = range(n)
    timestamp = datetime.utcnow()
    unit = None
    dimensions = {'instanceId': instance_id}
    
    ts = time.time()
    ret = cw.put_metric_data(namespace, name, value, timestamp, unit,
                             dimensions)
    delta = time.time() - ts
    
    return instance_id, ret, delta


def check_metrics(instance_id):
    n = FLAGS.get('stress_metrics_per_instance')
    interval = FLAGS.get('stress_interval')
    times = FLAGS.get('stress_times')
    period = 60
    start_time = TESTSTART
    end_time = TESTSTART + timedelta(seconds=(interval + 3) * times)
    namespace = TESTCASE
    statistics = 'SampleCount'
    metricnames = ["metric-%08d" % i for i in range(n)]
    dimensions = {'instanceId': instance_id}
    unit = None
    ret_value = True
    
    for metric_name in metricnames:
        ret = CW.get_metric_statistics(period, start_time, end_time,
                                       metric_name, namespace, statistics,
                                       dimensions, unit)
        
        metric_repr = "<Metric-%s-%s-%s>" % (namespace, metric_name,
                                             dimensions)
        # check number of datapoints
        count = 0
        for dp in ret:
            count += dp.get('SampleCount')
        if count != times:
            LOG.error("%s data loss? %s", metric_repr, ret)
            ret_value = False
            
        # check sufficient data in time
        ts = [dp.get('Timestamp') for dp in ret]
        ts_interval = set(map(lambda x, y: y - x, ts[:-1], ts[1:]))
        if ts_interval and ts_interval != set([timedelta(seconds=60)]):
            LOG.error("%s data in long interval %s", metric_repr, ret)
            ret_value = False

        LOG.debug("check - %s", ret)
        
    return instance_id, ret_value


def put_metrics(instance_id):
    return _put_metric(CW, instance_id)

def main():
    def get_now():
        stress_interval = FLAGS.get('stress_interval') 
        stress_times = FLAGS.get('stress_times')
        stress_backfill = FLAGS.get('stress_backfill')
        now = time.time() - stress_interval * stress_times
        
        while True:
            if stress_backfill:
                yield now
                now += stress_interval
            else:
                yield time.time()
    
    LOG.info("start test %s", TESTCASE)
    for k in FLAGS:
        LOG.info("Flags %s: %s", k, FLAGS.get(k))
        
    n_instances = FLAGS.get('stress_n_instances')
    
    # put metric data
    worker_pool = eventlet.GreenPool()
    instances = ["instance-%08d" % i for i in range(n_instances)]
    timer = get_now()
    
    iter_count = 0
    timestamp = 0
    while iter_count < FLAGS.get('stress_times'):
        now = timer.next()
        if now - timestamp > FLAGS.get('stress_interval'):
            iter_count += 1
            timestamp = now
            deltas = []
            LOG.info("iter count %d start", iter_count)
            for instance_id, ret, delta in worker_pool.imap(put_metrics,
                                                            instances):
                deltas.append(delta)
                LOG.debug("put metric %s for %s in %s", ret, instance_id,
                          delta)
            LOG.info("iter count %d avg/min/max(s): %f/ %f/ %f", iter_count,
                     sum(deltas) / len(deltas), min(deltas), max(deltas))
        else:
            time.sleep(1)

    # wait for data sync
    LOG.info("waiting for data sync")
    time.sleep(60)
    
    LOG.info("start to check statistics")
    # check metric data
    for instance_id, ret_value in worker_pool.imap(check_metrics, instances):
        pass

    LOG.info("end test %s", TESTCASE)


if __name__ == "__main__":
    pr = cProfile.Profile()
    pr.enable()
    # run test
    main()
    pr.disable()

    # parse profile data     
    s_io = StringIO.StringIO()
    ps = pstats.Stats(pr, stream=s_io).sort_stats('module')
    ps.print_stats()
    LOG.info("Profile Result:\n%s", s_io.getvalue())    
