#!/usr/bin/env python

# Copyright (c) 2012 Samsung SDS Co., LTD
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.

import eventlet
eventlet.monkey_patch()

import os
import sys

possible_topdir = os.path.normpath(os.path.join(os.path.abspath(sys.argv[0]),
                                                os.pardir, os.pardir))
if os.path.exists(os.path.join(possible_topdir, "synaps", "__init__.py")):
    sys.path.insert(0, possible_topdir)

from boto.ec2 import regioninfo
from boto.ec2.cloudwatch import CloudWatchConnection
from datetime import datetime, timedelta
import time

from synaps.openstack.common import cfg
from synaps import flags
from synaps import log as logging
from synaps import utils
from synaps.tests import get_cloudwatch_client


stress_cli_opts = [
    cfg.IntOpt('stress_interval',
               default=55,
               help='Stress test interval'),
    cfg.IntOpt('stress_times',
               default=10,
               help='Number of stress test set'),
    cfg.IntOpt('stress_n_instances',
               default=100,
               help='Number of instances for stress test'),
    cfg.IntOpt('stress_metrics_per_instance',
               default=12,
               help='Number of metrics per instance for stress test'),
]

FLAGS = flags.FLAGS
FLAGS.register_cli_opts(stress_cli_opts)
flags.FLAGS(sys.argv)

utils.default_flagfile()
logging.setup()
LOG = logging.getLogger()

TESTSTART = datetime.utcnow().replace(second=0, microsecond=0)
TESTCASE = "STRESS/" + datetime.now().strftime("%Y%m%d%H%M")

CW = get_cloudwatch_client()
    
def _put_metric(cw, instance_id):
    n = FLAGS.get('stress_metrics_per_instance')
    namespace = TESTCASE
    name = ["metric-%08d" % i for i in range(n)]
    value = range(n)
    timestamp = datetime.utcnow()
    unit = None
    dimensions = {'instanceId': instance_id}
    
    ts = time.time()
    ret = cw.put_metric_data(namespace, name, value, timestamp, unit,
                             dimensions)
    delta = time.time() - ts
    
    return instance_id, ret, delta


def check_metrics(instance_id):
    n = FLAGS.get('stress_metrics_per_instance')
    interval = FLAGS.get('stress_interval')
    times = FLAGS.get('stress_times')
    period = 60
    start_time = TESTSTART
    end_time = TESTSTART + timedelta(seconds=(interval + 3) * times)
    namespace = TESTCASE
    statistics = 'SampleCount'
    metricnames = ["metric-%08d" % i for i in range(n)]
    dimensions = {'instanceId': instance_id}
    unit = None
    ret_value = True
    
    for metric_name in metricnames:
        ret = CW.get_metric_statistics(period, start_time, end_time,
                                       metric_name, namespace, statistics,
                                       dimensions, unit)
        # check number of datapoints
        count = 0
        for dp in ret:
            count += dp.get('SampleCount')
        if count != times:
            LOG.error("data loss? %s", ret)
            ret_value = False
            
        # check sufficient data in time
        ts = [dp.get('Timestamp') for dp in ret]
        ts_interval = set(map(lambda x, y: y - x, ts[:-1], ts[1:]))
        if ts_interval != set([timedelta(seconds=60)]):
            LOG.error("data out of time? %s", ret)
            ret_value = False

        LOG.debug("check - %s", ret)
        
    return instance_id, ret_value


def put_metrics(instance_id):
    return _put_metric(CW, instance_id)

    

if __name__ == "__main__":
    LOG.info("start test %s", TESTCASE)
    n_instances = FLAGS.get('stress_n_instances')
    
    # put metric data
    worker_pool = eventlet.GreenPool()
    instances = ["instance-%08d" % i for i in range(n_instances)]
    
    iter_count = 0
    timestamp = 0
    while iter_count < FLAGS.get('stress_times'):
        now = time.time()
        if now - timestamp > FLAGS.get('stress_interval'):
            iter_count += 1
            timestamp = now
            deltas = []
            LOG.info("iter count %d start", iter_count)
            for instance_id, ret, delta in worker_pool.imap(put_metrics,
                                                            instances):
                deltas.append(delta)
                LOG.debug("put metric %s for %s in %s", ret, instance_id,
                          delta)
            LOG.info("iter count %d avg/min/max(s): %f/ %f/ %f", iter_count,
                     sum(deltas) / len(deltas), min(deltas), max(deltas))
        else:
            time.sleep(1)
    
    # wait for data sync
    LOG.info("waiting for data sync")
    time.sleep(60)
    
    LOG.info("start to check statistics")
    # check metric data
    for instance_id, ret in worker_pool.imap(check_metrics, instances):
        if ret:
            LOG.debug("%s OK", instance_id)
        else:
            LOG.error("%s data loss?", instance_id)

    LOG.info("end test %s", TESTCASE)
